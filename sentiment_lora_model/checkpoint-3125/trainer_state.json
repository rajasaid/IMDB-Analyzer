{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 3125,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.016,
      "grad_norm": 6.838124752044678,
      "learning_rate": 9.947733333333333e-05,
      "loss": 0.7012,
      "step": 50
    },
    {
      "epoch": 0.032,
      "grad_norm": 23.515810012817383,
      "learning_rate": 9.8944e-05,
      "loss": 0.5733,
      "step": 100
    },
    {
      "epoch": 0.048,
      "grad_norm": 22.559951782226562,
      "learning_rate": 9.841066666666667e-05,
      "loss": 0.3425,
      "step": 150
    },
    {
      "epoch": 0.064,
      "grad_norm": 2.6695125102996826,
      "learning_rate": 9.787733333333335e-05,
      "loss": 0.3799,
      "step": 200
    },
    {
      "epoch": 0.08,
      "grad_norm": 6.8079304695129395,
      "learning_rate": 9.734400000000001e-05,
      "loss": 0.3308,
      "step": 250
    },
    {
      "epoch": 0.096,
      "grad_norm": 3.7542107105255127,
      "learning_rate": 9.681066666666667e-05,
      "loss": 0.3676,
      "step": 300
    },
    {
      "epoch": 0.112,
      "grad_norm": 1.1523183584213257,
      "learning_rate": 9.627733333333335e-05,
      "loss": 0.3008,
      "step": 350
    },
    {
      "epoch": 0.128,
      "grad_norm": 8.880938529968262,
      "learning_rate": 9.5744e-05,
      "loss": 0.3337,
      "step": 400
    },
    {
      "epoch": 0.144,
      "grad_norm": 13.40857982635498,
      "learning_rate": 9.521066666666667e-05,
      "loss": 0.3542,
      "step": 450
    },
    {
      "epoch": 0.16,
      "grad_norm": 7.0944623947143555,
      "learning_rate": 9.467733333333334e-05,
      "loss": 0.3936,
      "step": 500
    },
    {
      "epoch": 0.176,
      "grad_norm": 24.016586303710938,
      "learning_rate": 9.414400000000001e-05,
      "loss": 0.367,
      "step": 550
    },
    {
      "epoch": 0.192,
      "grad_norm": 2.6999809741973877,
      "learning_rate": 9.361066666666667e-05,
      "loss": 0.2986,
      "step": 600
    },
    {
      "epoch": 0.208,
      "grad_norm": 6.4173359870910645,
      "learning_rate": 9.307733333333334e-05,
      "loss": 0.3474,
      "step": 650
    },
    {
      "epoch": 0.224,
      "grad_norm": 18.318119049072266,
      "learning_rate": 9.254400000000001e-05,
      "loss": 0.2767,
      "step": 700
    },
    {
      "epoch": 0.24,
      "grad_norm": 10.51401424407959,
      "learning_rate": 9.201066666666666e-05,
      "loss": 0.2874,
      "step": 750
    },
    {
      "epoch": 0.256,
      "grad_norm": 29.230384826660156,
      "learning_rate": 9.147733333333334e-05,
      "loss": 0.3078,
      "step": 800
    },
    {
      "epoch": 0.272,
      "grad_norm": 3.058279275894165,
      "learning_rate": 9.0944e-05,
      "loss": 0.3173,
      "step": 850
    },
    {
      "epoch": 0.288,
      "grad_norm": 18.356508255004883,
      "learning_rate": 9.041066666666666e-05,
      "loss": 0.3142,
      "step": 900
    },
    {
      "epoch": 0.304,
      "grad_norm": 4.12258243560791,
      "learning_rate": 8.987733333333334e-05,
      "loss": 0.3029,
      "step": 950
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.319678544998169,
      "learning_rate": 8.9344e-05,
      "loss": 0.3179,
      "step": 1000
    },
    {
      "epoch": 0.336,
      "grad_norm": 10.27933120727539,
      "learning_rate": 8.881066666666668e-05,
      "loss": 0.2773,
      "step": 1050
    },
    {
      "epoch": 0.352,
      "grad_norm": 16.247272491455078,
      "learning_rate": 8.827733333333333e-05,
      "loss": 0.3167,
      "step": 1100
    },
    {
      "epoch": 0.368,
      "grad_norm": 6.03266716003418,
      "learning_rate": 8.7744e-05,
      "loss": 0.2967,
      "step": 1150
    },
    {
      "epoch": 0.384,
      "grad_norm": 5.722747325897217,
      "learning_rate": 8.721066666666667e-05,
      "loss": 0.3668,
      "step": 1200
    },
    {
      "epoch": 0.4,
      "grad_norm": 4.500198841094971,
      "learning_rate": 8.667733333333333e-05,
      "loss": 0.2905,
      "step": 1250
    },
    {
      "epoch": 0.416,
      "grad_norm": 12.875337600708008,
      "learning_rate": 8.614400000000001e-05,
      "loss": 0.2983,
      "step": 1300
    },
    {
      "epoch": 0.432,
      "grad_norm": 1.8072478771209717,
      "learning_rate": 8.561066666666667e-05,
      "loss": 0.2876,
      "step": 1350
    },
    {
      "epoch": 0.448,
      "grad_norm": 9.13267707824707,
      "learning_rate": 8.507733333333335e-05,
      "loss": 0.3054,
      "step": 1400
    },
    {
      "epoch": 0.464,
      "grad_norm": 9.3217134475708,
      "learning_rate": 8.4544e-05,
      "loss": 0.3041,
      "step": 1450
    },
    {
      "epoch": 0.48,
      "grad_norm": 6.212055683135986,
      "learning_rate": 8.401066666666667e-05,
      "loss": 0.2692,
      "step": 1500
    },
    {
      "epoch": 0.496,
      "grad_norm": 5.110898971557617,
      "learning_rate": 8.347733333333333e-05,
      "loss": 0.3035,
      "step": 1550
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.5439571738243103,
      "learning_rate": 8.2944e-05,
      "loss": 0.2506,
      "step": 1600
    },
    {
      "epoch": 0.528,
      "grad_norm": 6.001575946807861,
      "learning_rate": 8.241066666666667e-05,
      "loss": 0.2434,
      "step": 1650
    },
    {
      "epoch": 0.544,
      "grad_norm": 9.540535926818848,
      "learning_rate": 8.187733333333334e-05,
      "loss": 0.2768,
      "step": 1700
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.5322093963623047,
      "learning_rate": 8.134400000000001e-05,
      "loss": 0.2586,
      "step": 1750
    },
    {
      "epoch": 0.576,
      "grad_norm": 11.578635215759277,
      "learning_rate": 8.081066666666666e-05,
      "loss": 0.2455,
      "step": 1800
    },
    {
      "epoch": 0.592,
      "grad_norm": 1.8502005338668823,
      "learning_rate": 8.027733333333334e-05,
      "loss": 0.3607,
      "step": 1850
    },
    {
      "epoch": 0.608,
      "grad_norm": 4.717032432556152,
      "learning_rate": 7.9744e-05,
      "loss": 0.278,
      "step": 1900
    },
    {
      "epoch": 0.624,
      "grad_norm": 8.421822547912598,
      "learning_rate": 7.921066666666666e-05,
      "loss": 0.2883,
      "step": 1950
    },
    {
      "epoch": 0.64,
      "grad_norm": 3.3003408908843994,
      "learning_rate": 7.867733333333334e-05,
      "loss": 0.2623,
      "step": 2000
    },
    {
      "epoch": 0.656,
      "grad_norm": 5.628565788269043,
      "learning_rate": 7.8144e-05,
      "loss": 0.2759,
      "step": 2050
    },
    {
      "epoch": 0.672,
      "grad_norm": 9.010584831237793,
      "learning_rate": 7.761066666666667e-05,
      "loss": 0.3047,
      "step": 2100
    },
    {
      "epoch": 0.688,
      "grad_norm": 3.9406421184539795,
      "learning_rate": 7.707733333333333e-05,
      "loss": 0.2554,
      "step": 2150
    },
    {
      "epoch": 0.704,
      "grad_norm": 7.031911373138428,
      "learning_rate": 7.6544e-05,
      "loss": 0.3255,
      "step": 2200
    },
    {
      "epoch": 0.72,
      "grad_norm": 8.668251037597656,
      "learning_rate": 7.601066666666668e-05,
      "loss": 0.2959,
      "step": 2250
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.4673945903778076,
      "learning_rate": 7.547733333333333e-05,
      "loss": 0.2543,
      "step": 2300
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.2662228047847748,
      "learning_rate": 7.4944e-05,
      "loss": 0.2753,
      "step": 2350
    },
    {
      "epoch": 0.768,
      "grad_norm": 11.955811500549316,
      "learning_rate": 7.441066666666667e-05,
      "loss": 0.3023,
      "step": 2400
    },
    {
      "epoch": 0.784,
      "grad_norm": 9.63178539276123,
      "learning_rate": 7.387733333333333e-05,
      "loss": 0.2474,
      "step": 2450
    },
    {
      "epoch": 0.8,
      "grad_norm": 7.066977024078369,
      "learning_rate": 7.334400000000001e-05,
      "loss": 0.3082,
      "step": 2500
    },
    {
      "epoch": 0.816,
      "grad_norm": 6.08420991897583,
      "learning_rate": 7.281066666666667e-05,
      "loss": 0.2667,
      "step": 2550
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.9521130323410034,
      "learning_rate": 7.227733333333335e-05,
      "loss": 0.2472,
      "step": 2600
    },
    {
      "epoch": 0.848,
      "grad_norm": 7.067314624786377,
      "learning_rate": 7.1744e-05,
      "loss": 0.2099,
      "step": 2650
    },
    {
      "epoch": 0.864,
      "grad_norm": 10.068836212158203,
      "learning_rate": 7.121066666666667e-05,
      "loss": 0.3229,
      "step": 2700
    },
    {
      "epoch": 0.88,
      "grad_norm": 5.373493671417236,
      "learning_rate": 7.067733333333334e-05,
      "loss": 0.2674,
      "step": 2750
    },
    {
      "epoch": 0.896,
      "grad_norm": 2.8840088844299316,
      "learning_rate": 7.0144e-05,
      "loss": 0.2828,
      "step": 2800
    },
    {
      "epoch": 0.912,
      "grad_norm": 9.502828598022461,
      "learning_rate": 6.961066666666667e-05,
      "loss": 0.2756,
      "step": 2850
    },
    {
      "epoch": 0.928,
      "grad_norm": 3.5335605144500732,
      "learning_rate": 6.907733333333334e-05,
      "loss": 0.2466,
      "step": 2900
    },
    {
      "epoch": 0.944,
      "grad_norm": 11.733832359313965,
      "learning_rate": 6.854400000000001e-05,
      "loss": 0.2211,
      "step": 2950
    },
    {
      "epoch": 0.96,
      "grad_norm": 14.729840278625488,
      "learning_rate": 6.801066666666666e-05,
      "loss": 0.2999,
      "step": 3000
    },
    {
      "epoch": 0.976,
      "grad_norm": 9.836812973022461,
      "learning_rate": 6.747733333333334e-05,
      "loss": 0.2854,
      "step": 3050
    },
    {
      "epoch": 0.992,
      "grad_norm": 3.922837495803833,
      "learning_rate": 6.6944e-05,
      "loss": 0.2736,
      "step": 3100
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.241610586643219,
      "eval_runtime": 143.0832,
      "eval_samples_per_second": 174.723,
      "eval_steps_per_second": 21.84,
      "step": 3125
    }
  ],
  "logging_steps": 50,
  "max_steps": 9375,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1684242585600000.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
