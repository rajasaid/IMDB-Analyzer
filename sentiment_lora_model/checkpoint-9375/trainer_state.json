{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 9375,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.016,
      "grad_norm": 6.838124752044678,
      "learning_rate": 9.947733333333333e-05,
      "loss": 0.7012,
      "step": 50
    },
    {
      "epoch": 0.032,
      "grad_norm": 23.515810012817383,
      "learning_rate": 9.8944e-05,
      "loss": 0.5733,
      "step": 100
    },
    {
      "epoch": 0.048,
      "grad_norm": 22.559951782226562,
      "learning_rate": 9.841066666666667e-05,
      "loss": 0.3425,
      "step": 150
    },
    {
      "epoch": 0.064,
      "grad_norm": 2.6695125102996826,
      "learning_rate": 9.787733333333335e-05,
      "loss": 0.3799,
      "step": 200
    },
    {
      "epoch": 0.08,
      "grad_norm": 6.8079304695129395,
      "learning_rate": 9.734400000000001e-05,
      "loss": 0.3308,
      "step": 250
    },
    {
      "epoch": 0.096,
      "grad_norm": 3.7542107105255127,
      "learning_rate": 9.681066666666667e-05,
      "loss": 0.3676,
      "step": 300
    },
    {
      "epoch": 0.112,
      "grad_norm": 1.1523183584213257,
      "learning_rate": 9.627733333333335e-05,
      "loss": 0.3008,
      "step": 350
    },
    {
      "epoch": 0.128,
      "grad_norm": 8.880938529968262,
      "learning_rate": 9.5744e-05,
      "loss": 0.3337,
      "step": 400
    },
    {
      "epoch": 0.144,
      "grad_norm": 13.40857982635498,
      "learning_rate": 9.521066666666667e-05,
      "loss": 0.3542,
      "step": 450
    },
    {
      "epoch": 0.16,
      "grad_norm": 7.0944623947143555,
      "learning_rate": 9.467733333333334e-05,
      "loss": 0.3936,
      "step": 500
    },
    {
      "epoch": 0.176,
      "grad_norm": 24.016586303710938,
      "learning_rate": 9.414400000000001e-05,
      "loss": 0.367,
      "step": 550
    },
    {
      "epoch": 0.192,
      "grad_norm": 2.6999809741973877,
      "learning_rate": 9.361066666666667e-05,
      "loss": 0.2986,
      "step": 600
    },
    {
      "epoch": 0.208,
      "grad_norm": 6.4173359870910645,
      "learning_rate": 9.307733333333334e-05,
      "loss": 0.3474,
      "step": 650
    },
    {
      "epoch": 0.224,
      "grad_norm": 18.318119049072266,
      "learning_rate": 9.254400000000001e-05,
      "loss": 0.2767,
      "step": 700
    },
    {
      "epoch": 0.24,
      "grad_norm": 10.51401424407959,
      "learning_rate": 9.201066666666666e-05,
      "loss": 0.2874,
      "step": 750
    },
    {
      "epoch": 0.256,
      "grad_norm": 29.230384826660156,
      "learning_rate": 9.147733333333334e-05,
      "loss": 0.3078,
      "step": 800
    },
    {
      "epoch": 0.272,
      "grad_norm": 3.058279275894165,
      "learning_rate": 9.0944e-05,
      "loss": 0.3173,
      "step": 850
    },
    {
      "epoch": 0.288,
      "grad_norm": 18.356508255004883,
      "learning_rate": 9.041066666666666e-05,
      "loss": 0.3142,
      "step": 900
    },
    {
      "epoch": 0.304,
      "grad_norm": 4.12258243560791,
      "learning_rate": 8.987733333333334e-05,
      "loss": 0.3029,
      "step": 950
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.319678544998169,
      "learning_rate": 8.9344e-05,
      "loss": 0.3179,
      "step": 1000
    },
    {
      "epoch": 0.336,
      "grad_norm": 10.27933120727539,
      "learning_rate": 8.881066666666668e-05,
      "loss": 0.2773,
      "step": 1050
    },
    {
      "epoch": 0.352,
      "grad_norm": 16.247272491455078,
      "learning_rate": 8.827733333333333e-05,
      "loss": 0.3167,
      "step": 1100
    },
    {
      "epoch": 0.368,
      "grad_norm": 6.03266716003418,
      "learning_rate": 8.7744e-05,
      "loss": 0.2967,
      "step": 1150
    },
    {
      "epoch": 0.384,
      "grad_norm": 5.722747325897217,
      "learning_rate": 8.721066666666667e-05,
      "loss": 0.3668,
      "step": 1200
    },
    {
      "epoch": 0.4,
      "grad_norm": 4.500198841094971,
      "learning_rate": 8.667733333333333e-05,
      "loss": 0.2905,
      "step": 1250
    },
    {
      "epoch": 0.416,
      "grad_norm": 12.875337600708008,
      "learning_rate": 8.614400000000001e-05,
      "loss": 0.2983,
      "step": 1300
    },
    {
      "epoch": 0.432,
      "grad_norm": 1.8072478771209717,
      "learning_rate": 8.561066666666667e-05,
      "loss": 0.2876,
      "step": 1350
    },
    {
      "epoch": 0.448,
      "grad_norm": 9.13267707824707,
      "learning_rate": 8.507733333333335e-05,
      "loss": 0.3054,
      "step": 1400
    },
    {
      "epoch": 0.464,
      "grad_norm": 9.3217134475708,
      "learning_rate": 8.4544e-05,
      "loss": 0.3041,
      "step": 1450
    },
    {
      "epoch": 0.48,
      "grad_norm": 6.212055683135986,
      "learning_rate": 8.401066666666667e-05,
      "loss": 0.2692,
      "step": 1500
    },
    {
      "epoch": 0.496,
      "grad_norm": 5.110898971557617,
      "learning_rate": 8.347733333333333e-05,
      "loss": 0.3035,
      "step": 1550
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.5439571738243103,
      "learning_rate": 8.2944e-05,
      "loss": 0.2506,
      "step": 1600
    },
    {
      "epoch": 0.528,
      "grad_norm": 6.001575946807861,
      "learning_rate": 8.241066666666667e-05,
      "loss": 0.2434,
      "step": 1650
    },
    {
      "epoch": 0.544,
      "grad_norm": 9.540535926818848,
      "learning_rate": 8.187733333333334e-05,
      "loss": 0.2768,
      "step": 1700
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.5322093963623047,
      "learning_rate": 8.134400000000001e-05,
      "loss": 0.2586,
      "step": 1750
    },
    {
      "epoch": 0.576,
      "grad_norm": 11.578635215759277,
      "learning_rate": 8.081066666666666e-05,
      "loss": 0.2455,
      "step": 1800
    },
    {
      "epoch": 0.592,
      "grad_norm": 1.8502005338668823,
      "learning_rate": 8.027733333333334e-05,
      "loss": 0.3607,
      "step": 1850
    },
    {
      "epoch": 0.608,
      "grad_norm": 4.717032432556152,
      "learning_rate": 7.9744e-05,
      "loss": 0.278,
      "step": 1900
    },
    {
      "epoch": 0.624,
      "grad_norm": 8.421822547912598,
      "learning_rate": 7.921066666666666e-05,
      "loss": 0.2883,
      "step": 1950
    },
    {
      "epoch": 0.64,
      "grad_norm": 3.3003408908843994,
      "learning_rate": 7.867733333333334e-05,
      "loss": 0.2623,
      "step": 2000
    },
    {
      "epoch": 0.656,
      "grad_norm": 5.628565788269043,
      "learning_rate": 7.8144e-05,
      "loss": 0.2759,
      "step": 2050
    },
    {
      "epoch": 0.672,
      "grad_norm": 9.010584831237793,
      "learning_rate": 7.761066666666667e-05,
      "loss": 0.3047,
      "step": 2100
    },
    {
      "epoch": 0.688,
      "grad_norm": 3.9406421184539795,
      "learning_rate": 7.707733333333333e-05,
      "loss": 0.2554,
      "step": 2150
    },
    {
      "epoch": 0.704,
      "grad_norm": 7.031911373138428,
      "learning_rate": 7.6544e-05,
      "loss": 0.3255,
      "step": 2200
    },
    {
      "epoch": 0.72,
      "grad_norm": 8.668251037597656,
      "learning_rate": 7.601066666666668e-05,
      "loss": 0.2959,
      "step": 2250
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.4673945903778076,
      "learning_rate": 7.547733333333333e-05,
      "loss": 0.2543,
      "step": 2300
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.2662228047847748,
      "learning_rate": 7.4944e-05,
      "loss": 0.2753,
      "step": 2350
    },
    {
      "epoch": 0.768,
      "grad_norm": 11.955811500549316,
      "learning_rate": 7.441066666666667e-05,
      "loss": 0.3023,
      "step": 2400
    },
    {
      "epoch": 0.784,
      "grad_norm": 9.63178539276123,
      "learning_rate": 7.387733333333333e-05,
      "loss": 0.2474,
      "step": 2450
    },
    {
      "epoch": 0.8,
      "grad_norm": 7.066977024078369,
      "learning_rate": 7.334400000000001e-05,
      "loss": 0.3082,
      "step": 2500
    },
    {
      "epoch": 0.816,
      "grad_norm": 6.08420991897583,
      "learning_rate": 7.281066666666667e-05,
      "loss": 0.2667,
      "step": 2550
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.9521130323410034,
      "learning_rate": 7.227733333333335e-05,
      "loss": 0.2472,
      "step": 2600
    },
    {
      "epoch": 0.848,
      "grad_norm": 7.067314624786377,
      "learning_rate": 7.1744e-05,
      "loss": 0.2099,
      "step": 2650
    },
    {
      "epoch": 0.864,
      "grad_norm": 10.068836212158203,
      "learning_rate": 7.121066666666667e-05,
      "loss": 0.3229,
      "step": 2700
    },
    {
      "epoch": 0.88,
      "grad_norm": 5.373493671417236,
      "learning_rate": 7.067733333333334e-05,
      "loss": 0.2674,
      "step": 2750
    },
    {
      "epoch": 0.896,
      "grad_norm": 2.8840088844299316,
      "learning_rate": 7.0144e-05,
      "loss": 0.2828,
      "step": 2800
    },
    {
      "epoch": 0.912,
      "grad_norm": 9.502828598022461,
      "learning_rate": 6.961066666666667e-05,
      "loss": 0.2756,
      "step": 2850
    },
    {
      "epoch": 0.928,
      "grad_norm": 3.5335605144500732,
      "learning_rate": 6.907733333333334e-05,
      "loss": 0.2466,
      "step": 2900
    },
    {
      "epoch": 0.944,
      "grad_norm": 11.733832359313965,
      "learning_rate": 6.854400000000001e-05,
      "loss": 0.2211,
      "step": 2950
    },
    {
      "epoch": 0.96,
      "grad_norm": 14.729840278625488,
      "learning_rate": 6.801066666666666e-05,
      "loss": 0.2999,
      "step": 3000
    },
    {
      "epoch": 0.976,
      "grad_norm": 9.836812973022461,
      "learning_rate": 6.747733333333334e-05,
      "loss": 0.2854,
      "step": 3050
    },
    {
      "epoch": 0.992,
      "grad_norm": 3.922837495803833,
      "learning_rate": 6.6944e-05,
      "loss": 0.2736,
      "step": 3100
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.241610586643219,
      "eval_runtime": 143.0832,
      "eval_samples_per_second": 174.723,
      "eval_steps_per_second": 21.84,
      "step": 3125
    },
    {
      "epoch": 1.008,
      "grad_norm": 7.175576686859131,
      "learning_rate": 6.641066666666666e-05,
      "loss": 0.3129,
      "step": 3150
    },
    {
      "epoch": 1.024,
      "grad_norm": 10.468106269836426,
      "learning_rate": 6.587733333333334e-05,
      "loss": 0.3112,
      "step": 3200
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.43172335624694824,
      "learning_rate": 6.5344e-05,
      "loss": 0.1821,
      "step": 3250
    },
    {
      "epoch": 1.056,
      "grad_norm": 2.236403226852417,
      "learning_rate": 6.481066666666668e-05,
      "loss": 0.306,
      "step": 3300
    },
    {
      "epoch": 1.072,
      "grad_norm": 22.69700050354004,
      "learning_rate": 6.427733333333333e-05,
      "loss": 0.3031,
      "step": 3350
    },
    {
      "epoch": 1.088,
      "grad_norm": 1.1821898221969604,
      "learning_rate": 6.3744e-05,
      "loss": 0.2599,
      "step": 3400
    },
    {
      "epoch": 1.104,
      "grad_norm": 1.00592839717865,
      "learning_rate": 6.321066666666667e-05,
      "loss": 0.2898,
      "step": 3450
    },
    {
      "epoch": 1.12,
      "grad_norm": 3.583630084991455,
      "learning_rate": 6.267733333333333e-05,
      "loss": 0.2859,
      "step": 3500
    },
    {
      "epoch": 1.1360000000000001,
      "grad_norm": 3.5449318885803223,
      "learning_rate": 6.2144e-05,
      "loss": 0.1897,
      "step": 3550
    },
    {
      "epoch": 1.152,
      "grad_norm": 9.517024040222168,
      "learning_rate": 6.161066666666667e-05,
      "loss": 0.2255,
      "step": 3600
    },
    {
      "epoch": 1.168,
      "grad_norm": 0.907505214214325,
      "learning_rate": 6.107733333333333e-05,
      "loss": 0.2512,
      "step": 3650
    },
    {
      "epoch": 1.184,
      "grad_norm": 2.0154099464416504,
      "learning_rate": 6.0544e-05,
      "loss": 0.2993,
      "step": 3700
    },
    {
      "epoch": 1.2,
      "grad_norm": 6.975033283233643,
      "learning_rate": 6.001066666666667e-05,
      "loss": 0.3385,
      "step": 3750
    },
    {
      "epoch": 1.216,
      "grad_norm": 1.5055233240127563,
      "learning_rate": 5.947733333333334e-05,
      "loss": 0.2243,
      "step": 3800
    },
    {
      "epoch": 1.232,
      "grad_norm": 2.671532392501831,
      "learning_rate": 5.8944e-05,
      "loss": 0.2487,
      "step": 3850
    },
    {
      "epoch": 1.248,
      "grad_norm": 9.057424545288086,
      "learning_rate": 5.8410666666666666e-05,
      "loss": 0.2301,
      "step": 3900
    },
    {
      "epoch": 1.264,
      "grad_norm": 13.66873836517334,
      "learning_rate": 5.7877333333333336e-05,
      "loss": 0.2256,
      "step": 3950
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.9859926700592041,
      "learning_rate": 5.7344e-05,
      "loss": 0.2362,
      "step": 4000
    },
    {
      "epoch": 1.296,
      "grad_norm": 0.48646336793899536,
      "learning_rate": 5.681066666666667e-05,
      "loss": 0.247,
      "step": 4050
    },
    {
      "epoch": 1.312,
      "grad_norm": 2.9693872928619385,
      "learning_rate": 5.627733333333334e-05,
      "loss": 0.3124,
      "step": 4100
    },
    {
      "epoch": 1.328,
      "grad_norm": 2.4742701053619385,
      "learning_rate": 5.574400000000001e-05,
      "loss": 0.1825,
      "step": 4150
    },
    {
      "epoch": 1.3439999999999999,
      "grad_norm": 6.666887283325195,
      "learning_rate": 5.521066666666666e-05,
      "loss": 0.3036,
      "step": 4200
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 6.395208358764648,
      "learning_rate": 5.467733333333334e-05,
      "loss": 0.2949,
      "step": 4250
    },
    {
      "epoch": 1.376,
      "grad_norm": 2.220046043395996,
      "learning_rate": 5.414400000000001e-05,
      "loss": 0.2472,
      "step": 4300
    },
    {
      "epoch": 1.392,
      "grad_norm": 14.32259750366211,
      "learning_rate": 5.3610666666666665e-05,
      "loss": 0.23,
      "step": 4350
    },
    {
      "epoch": 1.408,
      "grad_norm": 0.750356137752533,
      "learning_rate": 5.3077333333333334e-05,
      "loss": 0.2778,
      "step": 4400
    },
    {
      "epoch": 1.424,
      "grad_norm": 0.7693455219268799,
      "learning_rate": 5.2544000000000004e-05,
      "loss": 0.2469,
      "step": 4450
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.5403918027877808,
      "learning_rate": 5.201066666666667e-05,
      "loss": 0.2087,
      "step": 4500
    },
    {
      "epoch": 1.456,
      "grad_norm": 7.984134197235107,
      "learning_rate": 5.1477333333333336e-05,
      "loss": 0.2691,
      "step": 4550
    },
    {
      "epoch": 1.472,
      "grad_norm": 7.3538312911987305,
      "learning_rate": 5.0944000000000006e-05,
      "loss": 0.2554,
      "step": 4600
    },
    {
      "epoch": 1.488,
      "grad_norm": 7.5456929206848145,
      "learning_rate": 5.0410666666666675e-05,
      "loss": 0.2326,
      "step": 4650
    },
    {
      "epoch": 1.504,
      "grad_norm": 10.301654815673828,
      "learning_rate": 4.987733333333334e-05,
      "loss": 0.2869,
      "step": 4700
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.0916062593460083,
      "learning_rate": 4.9344e-05,
      "loss": 0.2633,
      "step": 4750
    },
    {
      "epoch": 1.536,
      "grad_norm": 3.2532577514648438,
      "learning_rate": 4.881066666666667e-05,
      "loss": 0.2638,
      "step": 4800
    },
    {
      "epoch": 1.552,
      "grad_norm": 6.235321998596191,
      "learning_rate": 4.827733333333333e-05,
      "loss": 0.2654,
      "step": 4850
    },
    {
      "epoch": 1.568,
      "grad_norm": 3.0543746948242188,
      "learning_rate": 4.7744e-05,
      "loss": 0.2114,
      "step": 4900
    },
    {
      "epoch": 1.584,
      "grad_norm": 5.477716445922852,
      "learning_rate": 4.721066666666667e-05,
      "loss": 0.1905,
      "step": 4950
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.2778432071208954,
      "learning_rate": 4.6677333333333335e-05,
      "loss": 0.3181,
      "step": 5000
    },
    {
      "epoch": 1.616,
      "grad_norm": 0.7976006269454956,
      "learning_rate": 4.6144000000000004e-05,
      "loss": 0.3077,
      "step": 5050
    },
    {
      "epoch": 1.6320000000000001,
      "grad_norm": 10.22553539276123,
      "learning_rate": 4.561066666666667e-05,
      "loss": 0.21,
      "step": 5100
    },
    {
      "epoch": 1.6480000000000001,
      "grad_norm": 9.746238708496094,
      "learning_rate": 4.5077333333333336e-05,
      "loss": 0.2793,
      "step": 5150
    },
    {
      "epoch": 1.6640000000000001,
      "grad_norm": 9.529462814331055,
      "learning_rate": 4.4544e-05,
      "loss": 0.2617,
      "step": 5200
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 6.536850452423096,
      "learning_rate": 4.401066666666667e-05,
      "loss": 0.2877,
      "step": 5250
    },
    {
      "epoch": 1.696,
      "grad_norm": 0.26636025309562683,
      "learning_rate": 4.347733333333334e-05,
      "loss": 0.26,
      "step": 5300
    },
    {
      "epoch": 1.712,
      "grad_norm": 3.320493698120117,
      "learning_rate": 4.2944e-05,
      "loss": 0.2604,
      "step": 5350
    },
    {
      "epoch": 1.728,
      "grad_norm": 11.71056842803955,
      "learning_rate": 4.241066666666667e-05,
      "loss": 0.2565,
      "step": 5400
    },
    {
      "epoch": 1.744,
      "grad_norm": 7.234687328338623,
      "learning_rate": 4.187733333333333e-05,
      "loss": 0.2756,
      "step": 5450
    },
    {
      "epoch": 1.76,
      "grad_norm": 17.490070343017578,
      "learning_rate": 4.1344e-05,
      "loss": 0.245,
      "step": 5500
    },
    {
      "epoch": 1.776,
      "grad_norm": 4.668026924133301,
      "learning_rate": 4.081066666666667e-05,
      "loss": 0.2875,
      "step": 5550
    },
    {
      "epoch": 1.792,
      "grad_norm": 8.07354736328125,
      "learning_rate": 4.0277333333333335e-05,
      "loss": 0.2821,
      "step": 5600
    },
    {
      "epoch": 1.808,
      "grad_norm": 1.4737013578414917,
      "learning_rate": 3.9744000000000004e-05,
      "loss": 0.2599,
      "step": 5650
    },
    {
      "epoch": 1.8239999999999998,
      "grad_norm": 3.1933376789093018,
      "learning_rate": 3.921066666666667e-05,
      "loss": 0.2356,
      "step": 5700
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.7084961533546448,
      "learning_rate": 3.867733333333334e-05,
      "loss": 0.2417,
      "step": 5750
    },
    {
      "epoch": 1.8559999999999999,
      "grad_norm": 0.24188418686389923,
      "learning_rate": 3.8144e-05,
      "loss": 0.3111,
      "step": 5800
    },
    {
      "epoch": 1.8719999999999999,
      "grad_norm": 0.5105798840522766,
      "learning_rate": 3.761066666666667e-05,
      "loss": 0.25,
      "step": 5850
    },
    {
      "epoch": 1.888,
      "grad_norm": 5.517001628875732,
      "learning_rate": 3.707733333333334e-05,
      "loss": 0.2287,
      "step": 5900
    },
    {
      "epoch": 1.904,
      "grad_norm": 7.941770076751709,
      "learning_rate": 3.6544e-05,
      "loss": 0.2485,
      "step": 5950
    },
    {
      "epoch": 1.92,
      "grad_norm": 5.705024719238281,
      "learning_rate": 3.601066666666667e-05,
      "loss": 0.2224,
      "step": 6000
    },
    {
      "epoch": 1.936,
      "grad_norm": 9.157315254211426,
      "learning_rate": 3.547733333333333e-05,
      "loss": 0.2811,
      "step": 6050
    },
    {
      "epoch": 1.952,
      "grad_norm": 1.1756902933120728,
      "learning_rate": 3.4943999999999996e-05,
      "loss": 0.197,
      "step": 6100
    },
    {
      "epoch": 1.968,
      "grad_norm": 1.125388503074646,
      "learning_rate": 3.4410666666666666e-05,
      "loss": 0.2445,
      "step": 6150
    },
    {
      "epoch": 1.984,
      "grad_norm": 1.1433336734771729,
      "learning_rate": 3.3877333333333335e-05,
      "loss": 0.2414,
      "step": 6200
    },
    {
      "epoch": 2.0,
      "grad_norm": 3.6280694007873535,
      "learning_rate": 3.3344000000000005e-05,
      "loss": 0.3294,
      "step": 6250
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.25906604528427124,
      "eval_runtime": 144.7288,
      "eval_samples_per_second": 172.737,
      "eval_steps_per_second": 21.592,
      "step": 6250
    },
    {
      "epoch": 2.016,
      "grad_norm": 0.746181309223175,
      "learning_rate": 3.281066666666667e-05,
      "loss": 0.2057,
      "step": 6300
    },
    {
      "epoch": 2.032,
      "grad_norm": 4.149717807769775,
      "learning_rate": 3.227733333333334e-05,
      "loss": 0.1671,
      "step": 6350
    },
    {
      "epoch": 2.048,
      "grad_norm": 6.149979591369629,
      "learning_rate": 3.1744e-05,
      "loss": 0.25,
      "step": 6400
    },
    {
      "epoch": 2.064,
      "grad_norm": 18.25267219543457,
      "learning_rate": 3.121066666666667e-05,
      "loss": 0.2659,
      "step": 6450
    },
    {
      "epoch": 2.08,
      "grad_norm": 8.7239351272583,
      "learning_rate": 3.067733333333334e-05,
      "loss": 0.2342,
      "step": 6500
    },
    {
      "epoch": 2.096,
      "grad_norm": 1.3386632204055786,
      "learning_rate": 3.0144e-05,
      "loss": 0.2575,
      "step": 6550
    },
    {
      "epoch": 2.112,
      "grad_norm": 4.346000671386719,
      "learning_rate": 2.961066666666667e-05,
      "loss": 0.1998,
      "step": 6600
    },
    {
      "epoch": 2.128,
      "grad_norm": 7.778889179229736,
      "learning_rate": 2.9077333333333334e-05,
      "loss": 0.3071,
      "step": 6650
    },
    {
      "epoch": 2.144,
      "grad_norm": 0.06315281987190247,
      "learning_rate": 2.8544000000000003e-05,
      "loss": 0.2147,
      "step": 6700
    },
    {
      "epoch": 2.16,
      "grad_norm": 4.092597007751465,
      "learning_rate": 2.801066666666667e-05,
      "loss": 0.2052,
      "step": 6750
    },
    {
      "epoch": 2.176,
      "grad_norm": 6.695794105529785,
      "learning_rate": 2.7477333333333332e-05,
      "loss": 0.2459,
      "step": 6800
    },
    {
      "epoch": 2.192,
      "grad_norm": 0.83662348985672,
      "learning_rate": 2.6944e-05,
      "loss": 0.3379,
      "step": 6850
    },
    {
      "epoch": 2.208,
      "grad_norm": 6.039536952972412,
      "learning_rate": 2.6410666666666668e-05,
      "loss": 0.244,
      "step": 6900
    },
    {
      "epoch": 2.224,
      "grad_norm": 4.610352516174316,
      "learning_rate": 2.5877333333333337e-05,
      "loss": 0.2283,
      "step": 6950
    },
    {
      "epoch": 2.24,
      "grad_norm": 2.1137897968292236,
      "learning_rate": 2.5344e-05,
      "loss": 0.2007,
      "step": 7000
    },
    {
      "epoch": 2.2560000000000002,
      "grad_norm": 7.628377914428711,
      "learning_rate": 2.481066666666667e-05,
      "loss": 0.2754,
      "step": 7050
    },
    {
      "epoch": 2.2720000000000002,
      "grad_norm": 5.534080982208252,
      "learning_rate": 2.4277333333333336e-05,
      "loss": 0.273,
      "step": 7100
    },
    {
      "epoch": 2.288,
      "grad_norm": 11.22890853881836,
      "learning_rate": 2.3744000000000002e-05,
      "loss": 0.2233,
      "step": 7150
    },
    {
      "epoch": 2.304,
      "grad_norm": 6.643343925476074,
      "learning_rate": 2.3210666666666668e-05,
      "loss": 0.2864,
      "step": 7200
    },
    {
      "epoch": 2.32,
      "grad_norm": 6.834530830383301,
      "learning_rate": 2.2677333333333334e-05,
      "loss": 0.299,
      "step": 7250
    },
    {
      "epoch": 2.336,
      "grad_norm": 3.5333893299102783,
      "learning_rate": 2.2144e-05,
      "loss": 0.2897,
      "step": 7300
    },
    {
      "epoch": 2.352,
      "grad_norm": 10.223771095275879,
      "learning_rate": 2.161066666666667e-05,
      "loss": 0.1913,
      "step": 7350
    },
    {
      "epoch": 2.368,
      "grad_norm": 0.16700482368469238,
      "learning_rate": 2.1077333333333336e-05,
      "loss": 0.2606,
      "step": 7400
    },
    {
      "epoch": 2.384,
      "grad_norm": 0.11528539657592773,
      "learning_rate": 2.0544000000000002e-05,
      "loss": 0.1931,
      "step": 7450
    },
    {
      "epoch": 2.4,
      "grad_norm": 7.46369743347168,
      "learning_rate": 2.0010666666666668e-05,
      "loss": 0.1808,
      "step": 7500
    },
    {
      "epoch": 2.416,
      "grad_norm": 8.794281959533691,
      "learning_rate": 1.9477333333333334e-05,
      "loss": 0.22,
      "step": 7550
    },
    {
      "epoch": 2.432,
      "grad_norm": 12.52108383178711,
      "learning_rate": 1.8944e-05,
      "loss": 0.2801,
      "step": 7600
    },
    {
      "epoch": 2.448,
      "grad_norm": 11.121870040893555,
      "learning_rate": 1.8410666666666666e-05,
      "loss": 0.2681,
      "step": 7650
    },
    {
      "epoch": 2.464,
      "grad_norm": 5.5817975997924805,
      "learning_rate": 1.7877333333333336e-05,
      "loss": 0.3029,
      "step": 7700
    },
    {
      "epoch": 2.48,
      "grad_norm": 4.7617974281311035,
      "learning_rate": 1.7344000000000002e-05,
      "loss": 0.2799,
      "step": 7750
    },
    {
      "epoch": 2.496,
      "grad_norm": 3.819744825363159,
      "learning_rate": 1.6810666666666665e-05,
      "loss": 0.2424,
      "step": 7800
    },
    {
      "epoch": 2.512,
      "grad_norm": 9.473057746887207,
      "learning_rate": 1.6277333333333334e-05,
      "loss": 0.2915,
      "step": 7850
    },
    {
      "epoch": 2.528,
      "grad_norm": 0.8419215083122253,
      "learning_rate": 1.5744e-05,
      "loss": 0.2519,
      "step": 7900
    },
    {
      "epoch": 2.544,
      "grad_norm": 4.438531875610352,
      "learning_rate": 1.5210666666666668e-05,
      "loss": 0.2033,
      "step": 7950
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.11805306375026703,
      "learning_rate": 1.4677333333333334e-05,
      "loss": 0.2357,
      "step": 8000
    },
    {
      "epoch": 2.576,
      "grad_norm": 6.025323390960693,
      "learning_rate": 1.4144000000000002e-05,
      "loss": 0.2472,
      "step": 8050
    },
    {
      "epoch": 2.592,
      "grad_norm": 8.386054992675781,
      "learning_rate": 1.3610666666666667e-05,
      "loss": 0.1858,
      "step": 8100
    },
    {
      "epoch": 2.608,
      "grad_norm": 3.4024951457977295,
      "learning_rate": 1.3077333333333333e-05,
      "loss": 0.2406,
      "step": 8150
    },
    {
      "epoch": 2.624,
      "grad_norm": 3.987602710723877,
      "learning_rate": 1.2544e-05,
      "loss": 0.2694,
      "step": 8200
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.08984149992465973,
      "learning_rate": 1.2010666666666667e-05,
      "loss": 0.2671,
      "step": 8250
    },
    {
      "epoch": 2.656,
      "grad_norm": 8.217302322387695,
      "learning_rate": 1.1477333333333334e-05,
      "loss": 0.183,
      "step": 8300
    },
    {
      "epoch": 2.672,
      "grad_norm": 16.300058364868164,
      "learning_rate": 1.0944e-05,
      "loss": 0.3211,
      "step": 8350
    },
    {
      "epoch": 2.6879999999999997,
      "grad_norm": 10.210309982299805,
      "learning_rate": 1.0410666666666667e-05,
      "loss": 0.3026,
      "step": 8400
    },
    {
      "epoch": 2.7039999999999997,
      "grad_norm": 6.781180381774902,
      "learning_rate": 9.877333333333335e-06,
      "loss": 0.2093,
      "step": 8450
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 7.925882816314697,
      "learning_rate": 9.344e-06,
      "loss": 0.233,
      "step": 8500
    },
    {
      "epoch": 2.7359999999999998,
      "grad_norm": 7.244707107543945,
      "learning_rate": 8.810666666666667e-06,
      "loss": 0.1967,
      "step": 8550
    },
    {
      "epoch": 2.752,
      "grad_norm": 5.019425392150879,
      "learning_rate": 8.277333333333335e-06,
      "loss": 0.1553,
      "step": 8600
    },
    {
      "epoch": 2.768,
      "grad_norm": 18.08307456970215,
      "learning_rate": 7.743999999999999e-06,
      "loss": 0.3153,
      "step": 8650
    },
    {
      "epoch": 2.784,
      "grad_norm": 11.051186561584473,
      "learning_rate": 7.210666666666667e-06,
      "loss": 0.2761,
      "step": 8700
    },
    {
      "epoch": 2.8,
      "grad_norm": 10.074840545654297,
      "learning_rate": 6.677333333333334e-06,
      "loss": 0.2602,
      "step": 8750
    },
    {
      "epoch": 2.816,
      "grad_norm": 4.921412467956543,
      "learning_rate": 6.144000000000001e-06,
      "loss": 0.2427,
      "step": 8800
    },
    {
      "epoch": 2.832,
      "grad_norm": 4.678401947021484,
      "learning_rate": 5.610666666666667e-06,
      "loss": 0.2872,
      "step": 8850
    },
    {
      "epoch": 2.848,
      "grad_norm": 6.964066982269287,
      "learning_rate": 5.077333333333333e-06,
      "loss": 0.1927,
      "step": 8900
    },
    {
      "epoch": 2.864,
      "grad_norm": 13.609637260437012,
      "learning_rate": 4.544e-06,
      "loss": 0.1655,
      "step": 8950
    },
    {
      "epoch": 2.88,
      "grad_norm": 3.3522894382476807,
      "learning_rate": 4.010666666666667e-06,
      "loss": 0.2497,
      "step": 9000
    },
    {
      "epoch": 2.896,
      "grad_norm": 5.692446231842041,
      "learning_rate": 3.477333333333334e-06,
      "loss": 0.2629,
      "step": 9050
    },
    {
      "epoch": 2.912,
      "grad_norm": 9.431533813476562,
      "learning_rate": 2.944e-06,
      "loss": 0.221,
      "step": 9100
    },
    {
      "epoch": 2.928,
      "grad_norm": 10.54439640045166,
      "learning_rate": 2.4106666666666667e-06,
      "loss": 0.2889,
      "step": 9150
    },
    {
      "epoch": 2.944,
      "grad_norm": 4.069260120391846,
      "learning_rate": 1.8773333333333334e-06,
      "loss": 0.2899,
      "step": 9200
    },
    {
      "epoch": 2.96,
      "grad_norm": 1.3657596111297607,
      "learning_rate": 1.3440000000000002e-06,
      "loss": 0.1709,
      "step": 9250
    },
    {
      "epoch": 2.976,
      "grad_norm": 8.162208557128906,
      "learning_rate": 8.106666666666667e-07,
      "loss": 0.2461,
      "step": 9300
    },
    {
      "epoch": 2.992,
      "grad_norm": 4.739002704620361,
      "learning_rate": 2.7733333333333333e-07,
      "loss": 0.2698,
      "step": 9350
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.24381351470947266,
      "eval_runtime": 149.2564,
      "eval_samples_per_second": 167.497,
      "eval_steps_per_second": 20.937,
      "step": 9375
    }
  ],
  "logging_steps": 50,
  "max_steps": 9375,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5052727756800000.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
